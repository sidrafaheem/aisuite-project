{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5lU5zLCpZtK+IpV3lek0z"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TK9ueGNMLIQg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##aisuite\n",
        "Simple, unified interface to multiple Generative AI providers.\n",
        "\n",
        "aisuite makes it easy for developers to use multiple LLM through a standardized interface. Using an interface similar to OpenAI's, aisuite makes it easy to interact with the most popular LLMs and compare the results. It is a thin wrapper around python client libraries, and allows creators to seamlessly swap out and test responses from different LLM providers without changing their code. Today, the library is primarily focussed on chat completions. We will expand it cover more use cases in near future.\n",
        "\n",
        "Currently supported providers are - OpenAI, Anthropic, Azure, Google, AWS, Groq, Mistral, HuggingFace Ollama, Sambanova and Watsonx. To maximize stability, aisuite uses either the HTTP endpoint or the SDK for making calls to the provider."
      ],
      "metadata": {
        "id": "x8w0I2HcLL1g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Installation\n",
        "Fiirst we run the command This installs all the provider-specific libraries:\n",
        "\n",
        "pip install 'aisuite[all]'\n",
        "\n",
        "httpx is a modern HTTP client for Python. To ensure compatibility, install version 0.24.1:\n",
        "\n",
        "pip install  httpx==0.24.1\n",
        "\n",
        "This version is stable and works well with libraries requiring HTTP requests."
      ],
      "metadata": {
        "id": "T8XVSG_LLY6X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttttlfTTFNXd",
        "outputId": "603d921b-00bf-4cb4-a3f3-9b19ae3a8a68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting aisuite[all]\n",
            "  Downloading aisuite-0.1.6-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting anthropic<0.31.0,>=0.30.1 (from aisuite[all])\n",
            "  Downloading anthropic-0.30.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting groq<0.10.0,>=0.9.0 (from aisuite[all])\n",
            "  Downloading groq-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.35.8 in /usr/local/lib/python3.10/dist-packages (from aisuite[all]) (1.54.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<0.31.0,>=0.30.1->aisuite[all]) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<0.31.0,>=0.30.1->aisuite[all]) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<0.31.0,>=0.30.1->aisuite[all]) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<0.31.0,>=0.30.1->aisuite[all]) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<0.31.0,>=0.30.1->aisuite[all]) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic<0.31.0,>=0.30.1->aisuite[all]) (1.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<0.31.0,>=0.30.1->aisuite[all]) (0.20.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from anthropic<0.31.0,>=0.30.1->aisuite[all]) (4.12.2)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.35.8->aisuite[all]) (4.66.6)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (2.27.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (0.26.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (2.2.3)\n",
            "Downloading anthropic-0.30.1-py3-none-any.whl (863 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m863.9/863.9 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groq-0.9.0-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aisuite-0.1.6-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: aisuite, groq, anthropic\n",
            "Successfully installed aisuite-0.1.6 anthropic-0.30.1 groq-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install 'aisuite[all]'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install httpx==0.24.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opkwyTZJGZlY",
        "outputId": "f346398c-4ced-421d-fdf4-5e9b36a8b221"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting httpx==0.24.1\n",
            "  Downloading httpx-0.24.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.1) (2024.8.30)\n",
            "Collecting httpcore<0.18.0,>=0.15.0 (from httpx==0.24.1)\n",
            "  Downloading httpcore-0.17.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.1) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.1) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx==0.24.1) (0.14.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx==0.24.1) (3.7.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx==0.24.1) (1.2.2)\n",
            "Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-0.17.3-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: httpcore, httpx\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.7\n",
            "    Uninstalling httpcore-1.0.7:\n",
            "      Successfully uninstalled httpcore-1.0.7\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "Successfully installed httpcore-0.17.3 httpx-0.24.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('myAPIkey66')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "collapsed": true,
        "id": "g-0NtWATHndw",
        "outputId": "69aa79b2-74f4-4254-8dcd-956c47f3db04"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'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'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Set up\n",
        "To get started, you will need API Keys for the providers you intend to use. You'll need to install the provider-specific library either separately or when installing aisuite.\n",
        "\n",
        "The API Keys can be set as environment variables, or can be passed as config to the aisuite Client constructor. You can use tools like python-dotenv or direnv to set the environment variables manually.\n",
        "\n",
        "In our case the API Key is set as a secret in colab secrets folder as GROQ_API_KEY, to get the secrets we will run:\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "api_key = userdata.get('GROQ_API_KEY')\n",
        "os.environ['GROQ_API_KEY'] = api_key"
      ],
      "metadata": {
        "id": "rxXF2p5SLhQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import aisuite as ai\n",
        "from google.colab import userdata\n",
        "\n",
        "api_key = userdata.get('myAPIkey66')\n",
        "os.environ['GROQ_API_KEY'] = api_key\n",
        "\n",
        "client = ai.Client()\n",
        "\n",
        "models = \"groq:llama-3.2-3b-instant\"\n",
        "models = \"groq:llama-3.2-3b-preview\"\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful agent, who answers in simple english.\"},\n",
        "    {\"role\": \"user\", \"content\": 'tell me about LLM in simple english and why it is helpfull'},\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=models,\n",
        "    messages=messages,\n",
        "    temperature=0.75\n",
        ")\n",
        "\n",
        "print(\"sidra faheem \")\n",
        "print(\"=\"*20)\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KW8Vr4nIGuA",
        "outputId": "b02f6b00-5525-49a3-d9db-ca43fb50136c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sidra faheem \n",
            "====================\n",
            "I'll explain LLM in simple words.\n",
            "\n",
            "**What is LLM?**\n",
            "\n",
            "LLM stands for Large Language Model. It's a type of computer program that can understand, generate, and process human language. LLM is like a super-powerful computer brain that can learn from lots of text data.\n",
            "\n",
            "**How does it work?**\n",
            "\n",
            "Imagine a huge library with millions of books. An LLM is like a robot that can read and learn from all those books. It can understand the meaning of words, sentences, and even whole paragraphs. Then, it can use that knowledge to generate new text, like writing a story or answering questions.\n",
            "\n",
            "**Why is LLM helpful?**\n",
            "\n",
            "LLM is helpful in many ways:\n",
            "\n",
            "1. **Answering questions**: LLM can quickly answer questions on a wide range of topics, like history, science, or sports.\n",
            "2. **Writing text**: LLM can generate text, like articles, stories, or even entire books.\n",
            "3. **Translation**: LLM can translate text from one language to another, helping people communicate across languages.\n",
            "4. **Language learning**: LLM can help people learn new languages by providing examples and practice exercises.\n",
            "5. **Chatbots**: LLM is used to create chatbots that can have conversations with humans, like customer service or virtual assistants.\n",
            "\n",
            "**Why is LLM useful for humans?**\n",
            "\n",
            "LLM is helpful for humans because it can:\n",
            "\n",
            "1. Save time: LLM can quickly answer questions or generate text, saving time and effort.\n",
            "2. Improve communication: LLM can help people communicate more effectively across languages and cultures.\n",
            "3. Enhance creativity: LLM can generate new ideas and text, inspiring creativity and innovation.\n",
            "\n",
            "I hope this helps you understand what LLM is and why it's helpful!\n"
          ]
        }
      ]
    }
  ]
}